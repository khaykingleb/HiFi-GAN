{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import wandb\n",
    "import json\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "\n",
    "from nv.spectrogram import MelSpectrogram\n",
    "from nv.collate_fn import LJSpeechCollator\n",
    "from nv.datasets import LJSpeechDataset\n",
    "from nv.trainer import *\n",
    "from nv.models import *\n",
    "from nv.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"configs/config_v1.json\"\n",
    "\n",
    "with open(f\"{config_path}\") as file:\n",
    "    config = AttrDict(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training process will be performed on cpu.\n",
      "Downloading and splitting the data.\n",
      "Initializing discriminator, generator, optimizers and lr_schedulers.\n"
     ]
    }
   ],
   "source": [
    "if config.use_wandb:\n",
    "    wandb.init(project=config.wandb_project_name)\n",
    "\n",
    "fix_seed(config)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if config.verbose:\n",
    "    print(f\"The training process will be performed on {device}.\")\n",
    "    print(\"Downloading and splitting the data.\")\n",
    "\n",
    "dataset = LJSpeechDataset(config.path_to_data)\n",
    "train_size = int(config.train_ratio * len(dataset))\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, \n",
    "    [train_size, len(dataset) - train_size],\n",
    "    generator=torch.Generator().manual_seed(config.seed)\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, \n",
    "    collate_fn=LJSpeechCollator(),\n",
    "    batch_size=config.batch_size, \n",
    "    #num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    collate_fn=LJSpeechCollator(),\n",
    "    batch_size=config.batch_size, \n",
    "    #num_workers=config.num_workers\n",
    ")\n",
    "\n",
    "melspectrogramer = MelSpectrogram(config, for_loss=False).to(device)\n",
    "melspectrogramer_for_loss = MelSpectrogram(config, for_loss=True).to(device)\n",
    "\n",
    "if config.verbose:\n",
    "    print(\"Initializing discriminator, generator, optimizers and lr_schedulers.\")\n",
    "\n",
    "generator = HiFiGenerator(config).to(device)\n",
    "trainable_params_generator = filter(\n",
    "    lambda param: param.requires_grad, generator.parameters()\n",
    ")\n",
    "optimizer_generator = torch.optim.AdamW(\n",
    "    trainable_params_generator, \n",
    "    betas=(config.adam_beta_1, config.adam_beta_2), \n",
    "    weight_decay=config.weight_decay, \n",
    "    lr=config.learning_rate\n",
    ") \n",
    "scheduler_generator = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer_generator, \n",
    "    gamma=config.gamma\n",
    ") \n",
    "\n",
    "discriminator = HiFiDiscriminator(config).to(device) \n",
    "trainable_params_discriminator = filter(\n",
    "    lambda param: param.requires_grad, discriminator.parameters()\n",
    ")\n",
    "optimizer_discriminator = torch.optim.AdamW(\n",
    "    trainable_params_discriminator, \n",
    "    betas=(config.adam_beta_1, config.adam_beta_2), \n",
    "    weight_decay=config.weight_decay, \n",
    "    lr=config.learning_rate\n",
    ") \n",
    "scheduler_discriminator = torch.optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer_discriminator, \n",
    "    gamma=config.gamma\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nv.trainer import *\n",
    "from nv.losses import *\n",
    "\n",
    "def train(\n",
    "    config, \n",
    "    train_dataloader, \n",
    "    val_dataloader,\n",
    "    generator, \n",
    "    optimizer_generator, \n",
    "    scheduler_generator, \n",
    "    discriminator, \n",
    "    optimizer_discriminator, \n",
    "    scheduler_discriminator, \n",
    "    melspectrogramer, \n",
    "    melspectrogramer_for_loss\n",
    "):  \n",
    "    history_val_melspec_loss = []\n",
    "    epoch = 0\n",
    "\n",
    "    #for epoch in tqdm(range(config.num_epoch)):\n",
    "    while True:\n",
    "        epoch += 1\n",
    "\n",
    "        train_melspec_loss = train_epoch(\n",
    "            config, train_dataloader,\n",
    "            generator, optimizer_generator, scheduler_generator, \n",
    "            discriminator, optimizer_discriminator, scheduler_discriminator, \n",
    "            melspectrogramer, melspectrogramer_for_loss\n",
    "        )\n",
    "\n",
    "        val_melspec_loss = validate_epoch(\n",
    "            config, val_dataloader,\n",
    "            generator, optimizer_generator, scheduler_generator, \n",
    "            discriminator, optimizer_discriminator, scheduler_discriminator, \n",
    "            melspectrogramer, melspectrogramer_for_loss\n",
    "        )\n",
    "\n",
    "        history_val_melspec_loss.append(val_melspec_loss)\n",
    "\n",
    "        if config.use_wandb:             \n",
    "            wandb.log({\n",
    "                \"Epoch\": epoch,\n",
    "                \"Global Train Melspectrogram Loss\": train_melspec_loss,\n",
    "                \"Global Validation Melspectrogram Loss\": val_melspec_loss\n",
    "            })  \n",
    "        \n",
    "        #if val_melspec_loss <= min(history_val_melspec_loss):\n",
    "        state = {\n",
    "            \"generator\": generator.state_dict(),\n",
    "            \"generator_arch\": type(generator).__name__,\n",
    "            \"optimizer_generator\": optimizer_generator.state_dict(),\n",
    "            \"discriminator\": discriminator.state_dict(),\n",
    "            \"discriminator_arch\": type(discriminator).__name__,\n",
    "            \"optimizer_discriminator\": optimizer_generator.state_dict(),\n",
    "            \"config\": config\n",
    "        }\n",
    "        torch.save(state, config.path_to_save + \"/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    config, \n",
    "    train_dataloader,\n",
    "    generator, \n",
    "    optimizer_generator, \n",
    "    scheduler_generator, \n",
    "    discriminator, \n",
    "    optimizer_discriminator, \n",
    "    scheduler_discriminator, \n",
    "    melspectrogramer, \n",
    "    melspectrogramer_for_loss\n",
    "):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "\n",
    "    adversarial_loss = AdversarialLoss()\n",
    "    feature_loss = FeatureMatchingLoss()\n",
    "    melspec_loss = MelSpectrogramLoss()\n",
    "\n",
    "    discriminator_loss = DiscriminatorLoss()\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        batch = prepare_batch(batch, melspectrogramer, melspectrogramer_for_loss, device, for_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import *\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    break\n",
    "    batch = prepare_batch(batch, melspectrogramer, aligner, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/functional.py:572: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  ../aten/src/ATen/native/SpectralOps.cpp:659.)\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "batch = prepare_batch(batch, melspectrogramer, melspectrogramer_loss, device, for_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_loss = AdversarialLoss()\n",
    "feature_loss = FeatureMatchingLoss()\n",
    "melspec_loss = MelSpectrogramLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_real, melspec_real = batch.waveform, batch.melspec\n",
    "\n",
    "wav_fake = generator(melspec_real)\n",
    "melspec_fake = melspectrogramer_loss(wav_fake)\n",
    "\n",
    "out_discr = discriminator(wav_real, wav_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_adv = adversarial_loss(out_discr[\"outs_fake\"])\n",
    "loss_fm = feature_loss(out_discr[\"feature_maps_real\"], out_discr[\"feature_maps_fake\"])\n",
    "loss_mel = melspec_loss(melspec_real, melspec_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_generator = loss_adv + 2 * loss_fm + 45 * loss_mel\n",
    "loss_generator.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7f88f9217fd0>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py:154: UserWarning: Error detected in MulBackward0. No forward pass information available. Enable detect anomaly during forward pass for more information. (Triggered internally at  ../torch/csrc/autograd/python_anomaly_mode.cpp:85.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-073114605690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "loss_generator.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch.melspec_loss, melspec_fake)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
